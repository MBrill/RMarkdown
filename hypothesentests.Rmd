---
title: "Hypothesentests mit einer Stichprobe"
author: "Manfred Brill"
date: "Sommersemester 2021"
output: 
  html_notebook:
    highlight: pygments
    number_sections: yes
    theme: cosmo
    toc: yes
    encoding: utf-8   
  html_document: 
    
    fig_caption: yes
    highlight: pygments
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_float: yes  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
suppressPackageStartupMessages(library(dplyr))
library(tidyverse)

library(RColorBrewer)
myPalette <- brewer.pal(5, "YlGn")
# Ausgabe von double-Werte mit  zwei Stellen hinter dem Komma
options(digits=4)
```

# Hypothesentests mit einer Stichprobe und bekannter Standardabweichung

## Zweiseitige Hypothesentests
In den Folien wird ein Beispiel mit der Füllmenge von Flaschen in 
einer Brauerei betrachtet. Wir haben eine 
Füllmenge und wir möchten mit Hilfe einer Stichprobe
überprüfen, ob diese Füllmenge eingehalten wird.
Dazu besetzen wir einige Variablen, die sowohl
die vorgegebenen Mengen und die Ergebnisse der Stichprobe
enthalten.

```{r stichprobe, include=TRUE, echo=TRUE}
mu_h0 <- 500.0
n <- 25
mu_est <- 499.28

sigma2 <- 2.25
sigma_0 <- sqrt(sigma2)
```

Als Nullhypothese gehen wir davon aus,
dass die mittlere Füllhöhe der Flaschen durch `r mu_h0` cm$^3$ gegeben ist.
Ab sofort lassen wir die Einheit der Füllhöhe im Text weg.

Wir überprüfen diese Nullhypothese H0 gegen die Gegenhypothese
H1, dass die mittlere Füllhöhe nicht durch diesen Betrag gegeben ist.
Einen solchen Hypothesentest nennen wir **zweiseitiger Hypothesentest**.

Wir gehen bei unserem Test davon aus, dass wir in einer
Stichprobe mit `r n` Flaschen durch das arithmetische Mittel 
`r mu_est` als Punktschätzer erhalten haben.
Aus Unterlagen der Qualitätssicherung
wissen wir, dass die Füllhöhe normalverteilt ist, mit einer Varianz
von `r sigma2`, also einer Standardabweichung von `r sigma_0`.
Wenn wir jetzt noch das Konfidenzniveau festlegen haben wir alle Daten
um das Prognoseintervall zu berechnen und unseren Hypothesentest durchzuführen.

```{r prognose99,  message=FALSE, echo=TRUE, results='asis'}
sem <- sigma_0/sqrt(n)
alpha <- 0.01

qu <- 1.0 - alpha/2.0
ql <- alpha/2.0

ub <- qnorm(qu)
lb <- qnorm(ql)

# Grenzen
b <- ub * sem
a <- -b

# Intervall
prognose <- mu_est + c(a, b)
```

Das Prognose-Intervall mit Irrtumswahrscheinlichkeit `r alpha`, zum Niveau `r 1 - alpha`, ist gegeben als [`r prognose`].

Mit 99 Prozent Wahrscheinlichkeit liegt der von uns angenommene Wert von 
`r mu_h0` aus der Nullhypothese in diesem Prognose-Intervall. Dann lehnen wir die Nullhypothese **nicht** ab.

Wir verändern die Irrtumswahrscheinlichkeit auf 0.05 und berechnen dafür das Prognose-Intervall:

```{r prognose95,  message=FALSE, echo=TRUE, results='asis'}
alpha <- 0.05

qu <- 1.0 - alpha/2
ql <- alpha/2.0

ub <- qnorm(qu)
lb <- qnorm(ql)

# Grenzen
b <- ub * sem
a <- -b

# Intervall
prognose <- mu_est + c(a, b)
```

Das Prognose-Intervall mit Irrtumswahrscheinlichkeit `r alpha`, zum Niveau `r 1 - alpha`, ist gegeben als [`r prognose`]. Der Wert von 500 aus der Nullhypothese liegt nicht in diesem Intervall. Dann ist der Mittelwert, den wir für das Prognose-Intervall verwenden haben zu unwahrscheinlich - wir verwerfen die Nullhypothese und nehmen die Gegenhypothese, dass die mittlere Füllmenge **nicht** durch 500 gegeben ist, an.

Allgemein bezeichnen wir das in den Beispielen berechnete Prognoseintervall
als den **Annahmebereich**. Liegt der Wert aus der Nullhypothse in diesem Intervall,
dann verwerfen wir die Nullhypothese nicht. Das Komplement des Prognoseintervalls
bezeichnen wir aus offensichtlichen Gründen als **Verwerfungsbereich**.

## Einseitige Hypothesentests

Das Eichamt vermutet vermutlich eher, dass die Füllhöhe kleiner als der 
Wert `r mu_h0` ist. Oder das Unternehmen selbst vermutet eventuell,
dass die Füllhöhe zu hoch ist. Solche Thesen können wir mit Hilfe
von **einseitigen Hypothesentests** überprüfen. Hier verwenden wir als
Gegenhypothese eine Ungleichung, entweder 
mit dem Vergleichsoperator > oder <.

Bei der Berechnung des **Annahme-** und **Verwerfungsbereicsh**
müssen wir die restlichen Flächen nicht links und rechts anordnen
sondern wir arbeiten mit dem Wert 1 - $\alpha$. 
Für die Nullhypothese H0 verwenden wir als Beispiel
\[
H_0: \mu \geq 500.
\]
Dann ist die Gegenhypothese durch
\[
H_1: \mu < 500
\]
gegeben.

Das Vorgehen ist analog wie beim zweiseitigen Test,
wir berechnen als Annahmebereich ein Intervall, das 
bei $-\infty$ auf dem Zahlenstrahl beginnt und
als rechte Grenze durch das Quantil zur Warscheinlichkeit 1 - $\alpha$
gegeben ist. Als Irrtumswahrscheinlichkeit verwenden
wir 5%.

```{r onesided,  message=FALSE, echo=TRUE, results='asis'}
alpha <- 0.05

qu <- 1.0 - alpha
ub <- qnorm(qu)

# Obere Grenze des Annahmebereichs
b <- ub * sem

# Intervall
prognose <- mu_est + b
```

Wir erhalten als rechte Grenze des Annahmebereichs den Wert
`r prognose`. 
Mit dem Niveau `r 1 - alpha` verwerfen wir die Nullhypothese und
nehmen die Gegenhypothese an, dass die Füllhöhe weniger als 500 beträgt.

Bemerkung: wenn wir für die Irrtumswahrscheinlichkeit 1% verwenden
wird auch für dieses Niveau die Nullhypothese verworfen, was Sie überprüfen sollten!

## Gauß-Test

Bevor wir zu dem Fall gehen, dass wir bei der Durchführung des Hypothesentests die Standardabweichung nicht kennen
formulieren wir den Ablauf des beschriebenen Hypothesentests
allgemein. Wir werden bemerken, dass dieser Ablauf so gut wie immer
eingehalten wird. Wir nennen einen solchen Test *Gauß-Test*.

1. Wir formulieren die Nullhypothese H0 und die Gegenhypothese H1.
1. Wir legen ein Signifikanzniveau 1 - $\alpha$ bzw. die Irrtumswahrscheinlichkeit $\alpha$ fest. 
Damit können wir den Annahme- bzw. den Verwerfungsbereich angeben.
1. Wir verwerfen die Nullhypothese, falls der Wert der aus der Nullhypothese nicht im Annahmebereich liegt. Liegt der Wert  im Annahmebereich verwerfen wir die Nullhypothese nicht.

## p-Werte
Neben den beiden Bereichen, die wir für die Annahme oder für das Verwerfen
einer Nullhypothesn aus den Prognose-Intervallen bilden wird in der Praxis
sehr häufig mit dem sogenannten **p-Wert**, im Englischen **p-value**, gearbeitet. Manchmal finden wir auch die Bezeichnung
**observed significance level**.
Dieser Wert ist die Antwort auf die Frage,
wie wahrscheinlich der Wert der Punktschätzung ist, wenn
die Nullhypothese wahr ist. 

Für einen  zweiseitigen Hypothesentest können wir dieses p
berechnen. Der Wert ist gegeben als die Wahrscheinlichkeit,
dass wir den berechnen Wert der Punktschätzung oder noch
unwahrscheinlichere finden. Diese Berechnung können
wir mit der Dichte, hier der Normalverteilung durchführen.
Ist der berechnete p-Wert kleiner als die Irrtumswahrscheinlichkeit
verwerfen wir die Nullhypothese.

```{r pvalue,  message=FALSE, echo=TRUE, results='asis'}
p <- 2.0 * pnorm(mu_est, mean = mu_h0, sd = sem)
```

In unserem Beispiel mit den Füllhöhen erhalten für den zweiseitigen Test den Wert `r p` für den p-Wert.
Da er größer ist als 1% verwerfen wir für diese Irrtumswahrscheinlichkeit
die Nullhypothese nicht - dieses Ergebnis hatten bereits mit Hilfe des Annahmebereichs
erzielt. Für die Irrtumswahrscheinlichkeit 5%
verwerfen wir die Nullhypothese. Denn der p-Wert ist kleiner als 0.05.

Auch für den einseitigen Hypothesentest können wir den p-Wert
berechnen, hier verschwindet allerdings der Faktor 2.

```{r pvalueos,  message=FALSE, echo=TRUE, results='asis'}
p <- pnorm(mu_est, mean = mu_h0, sd = sem)
```

Hier erhalten wir für p den Wert `r p`. Wie schon vorher entschieden verwerfen
wir für beide Werte von $\alpha$.

# Hypothesentest mit unbekannter Standardabweichung

## t-Tests

In der Praxis werden wir die Standardabweichung für die Grundgesamtheit
vermutlich nicht kennen. In diesem Fall führen wir einen sogenannten t-Test
durch. Der Ablauf ist genauso wie oben, außer dass wir jetzt zwei
Punktschätzer, für den Erwartungswert und die Varianz, verwenden
und statt einer Normalverteilung die t-Verteilung einsetzen.

Da uns keine konkreten Werte für die Füllhöhen in der Brauerei
vorliegen verwenden wir stattdessen Stichprobenwerte 
über die Reißfestigkeit, die wir in den Datensätzen
in OLAT finden, die wir bereits als Beispiel für die
Berechnung von Punkt- und Intervallschätzern eingesetzt haben.
Wir weisen die Werte direkt der Variable *festigkeit* zu,
dann müssen wir die Werte nicht einlesen.

Wir führen einen zweiseitigen Hypothesentest aus, dabei 
untersuchen wir die Nullhypothese, dass der Erwartungswert
der normalverteilten Grundgesamtheit durch 100 gegeben ist.
Als Irrtumswahrscheinlichkeit verwenden wir 5%.

Wir berechnen den Annahmebereich mit Hilfe der Quantile der t-Verteilung.
Sonst entsteht kein großer Unterschied im verwenden R-Quellcode.

```{r ttestreiss,  message=FALSE, echo=TRUE, warnings=FALSE}
festigkeit <- c(106, 102, 94, 107, 99, 103, 98, 101, 102, 90)

mu_h0 <- 100.0
mu_est <- mean(festigkeit)
var_est <- var(festigkeit)
sd_est <- sd(festigkeit)

sem <- sd_est/sqrt(n)

alpha = 0.05

qu <- 1.0 - alpha/2
ql <- alpha/2.0

ub <- qt(qu, df = n-1)
lb <- qt(ql, df = n-1)

# Grenzen
b <- ub * sem
a <- -b

# Intervall
prognose <- mu_est + c(a, b)
``` 

Der Annahmebereich mit Irrtumswahrscheinlichkeit `r alpha`, zum Niveau `r 1 - alpha`, ist gegeben als [`r prognose`]. Der Wert von `r mu_h0` aus der Nullhypothese liegt in diesem Bereich. Wir verwerfen die Nullhypothese nicht.

Auch für diesen Fall können wir p-Werte berechnen, wir verwenden hier
die Funktion *tnorm* für die t-Verteilung. Und auch einseitige Hypothesentests
verlaufen analog wie bisher.

## Hypothesentests für binomialverteilte Größen

Die Binomialverteilung wird sehr häufig in der Qualitätssicherung
oder allgemein für die Modellierung von Anteilen in einer Grundgesamtheit eingesetzt. 

```{r binomData,  message=FALSE, echo=FALSE, warnings=FALSE}
p0 <- 0.03
n <- 500
alpha <- 0.05

p <- 20/n
``` 

Als Beispiel betrachten wir einen Hersteller von Bauteilen,
der angibt, dass der Anteil fehlerhafter Stücke in seiner Produktion
höchstens 3% beträgt. Wir ziehen eine Stichprobe, um diese Angabe
zu prüfen und entnehmen der Produktion `r n` Bauteile.
Die Nullhypothese ist jetzt, dass der Parameter p der binomialverteilten Zufallsvariable, die die Anzahl der defekten
Bauteile modelliert durch p=`r p0` gegeben ist.
Die Gegenhypothese lautet, dass p ungleich `r p0` ist.
Wir legen eine Irrtumswahrscheinlichkeit von `r alpha` fest.

Wenn wir wie schon in der Wahrscheinlichkeitsrechnung
eine Zählvariable verwenden, dann berechnen wir mit dem
arithmetischen Mittel über diese Zählvariable eine Punktschätzung
für p. Ist n groß genug, dann können wir die Binomialverteilung
durch eine Normalverteilung ersetzen.

Bevor wir dies durchführen rufen wir uns einige Fakten für die
Binomialverteilung in Erinnerung:
\[
E(X) = n \cdot p, \sigma^2 = \frac{p(1-p)}{n}.
\]
Mit dem arithmetischen Mittel berechnen wir eine Schätzung
p, die Standardabweichung können wir mit dem in der Nullhypothese
angegebenen Anteil berechnen und führen anschließend einen Gauß-Test
für diese Statistik durch:
\[
H_0: p = p_0, H_1: p \neq p_0.
\]
Wir normalisieren die verwendete Zufallsvariable und berechnen
die Zahl z, die *Statistik*:
\[
z = \frac{p-p_0}{\sqrt{\frac{p(1-p)}{n}}}
\]
Da z standardnormalverteilt ist können wir die Quantile der Standardnormalverteilung verwenden um den Annahmebereich zu berechnen
und den Hypothesentest durchzuführen.

Für die Durchführung des Hypothesentests gehen wir davon aus,
dass wir in der Stichprobe mit n=`r n` Bauteilen
20 defekte Bauteile gefunden haben. Dann ist der Punktschätzer
als `r p` gegeben.

```{r binomtest,  message=FALSE, echo=TRUE, warnings=FALSE}
sigma <- sqrt((p0*(1-p0))/n)

z <- (p-p0)/sigma

# Grenzen
qu <- 1.0 - alpha/2
b <- qnorm(qu)
a <- -b

# Intervall
prognose <- c(a, b)
``` 

Für die Statistik z erhalten wir den Wert `r z`, der Annahmebereich
ist als [`r prognose`] gegeben. Wir verwerfen die Nullhypothese nicht.

Wie bereits bei den Gauß- und t-Tests können wir auch den p-Wert
für die Statistik berechnen. Dazu verwenden wir die Funktion *pnorm*:

```{r binompv,  message=FALSE, echo=TRUE, warnings=FALSE}
pval <- 2.0*pnorm(z, lower.tail=FALSE)
``` 

Der p-Wert ist `r pval` und damit größer als die
vorgegebene Irrtumswahrscheinlichkeit von 0.05. 

# Hypothesentests in R

## Der Gauß-Test mit der Funktion *z.test*

Natürlich gibt es die Tests die wir vorgestellt haben (und noch viele mehr) als Funktionen in R. Den Hypothesentest mit bekannter Standardabweichung findet man nicht im Default-Paket *stats*, da in der Praxis meist ein t-Test durchgeführt wird. Im Package *TeachingDemos* gibt es aber die Funktion *z.test*, mit der 
wir diesen Test durchführen können. In der Dokumentation dieser Funktion findet man schon den Hinweis, dass die Funktion nur für *akademische* Zwecke implementiert wurde und man in der Praxis den t-Test mit Hilfe der Funktion *t.test* verwenden soll.

Beide Funktionen erhalten als Argument die komplette Stichprobe. Wir können die Nullhypothese und die Irrtumswahrscheinlichkeit übergeben, als Default wird
von einer Irrtumswahrscheinlichkeit von 5% ausgegangen.
Da wir eine Stichprobe benötigen verwenden wir die 10 Werte für die Untersuchung der Reißfestigkeit, die wir bereits beim t-Test verwendet haben.
Statt alle Variablen selbst zu berechnen übergeben wir die Stichprobe
und verwenden anschließend die Ergebnisse dieser Funktion.
Um die Funktionen zu verwenden laden wir spätestens jetzt
das Package *TeachingDemos*.

```{r loadTeachingDemo,  message=FALSE, echo=FALSE, warnings=FALSE, include=FALSE}
suppressPackageStartupMessages(library(TeachingDemos))
library(TeachingDemos)
```

Wir rufen die Funktion *z.test* auf, speichern das Ergebnis auf einem Objekt
und geben dieses Objekt auf der Konsole aus:

```{r reissgauss,  message=FALSE, echo=TRUE, warnings=FALSE}
sigma_0 <- 5.0
alpha <- 0.05
(res <- z.test(festigkeit, mu=100, sigma_0, 
              conf.level=1-alpha))
``` 

```{r reissgaussvar,  message=FALSE, echo=FALSE, warnings=FALSE}
pv <- res$p.value
statistic <- res$estimate
ci <- res$conf.int
``` 

Wir übergeben den Wert für die Nullhypothese, die bekannte Standardabweichung
und das Konfidenzniveau. In der Struktur, die wir als Ergebnis erhalten
finden wir alle Angaben, die wir benötigen um den Test zu entscheiden.
Wir finden den Punktschätzer für den Erwartungswert und den Annahmebereich,
genauso wie den berechneten p-Wert. Mit Hilfe von beiden Angaben entscheiden wir, dass wir die Nullhypothese nicht verwerfen.
Als p-Wert erhalten wir `r pv`.

Im Beispiel ist der Punktschätzer für den Erwartungswert wie schon
uns selbst oben berechnet durch `r statistic` gegeben,
der Annahmebereich ist das Intervall [`r ci`].

Wir können die Irrtumswahrscheinlichkeit verändern und führen
anschließend den Test mit der Funktio nochmals durch:

```{r reissgauss99,  message=FALSE, echo=TRUE, warnings=FALSE}
alpha <- 0.01
(res <- z.test(festigkeit, mu=100, sigma_0, 
              conf.level=1-alpha))
``` 

```{r reissgaussvar99,  message=FALSE, echo=FALSE, warnings=FALSE}
pv <- res$p.value
statistic <- res$estimate
ci <- res$conf.int
``` 


Für das Niveau `r 100*(1 - alpha)` % 
erhalten wir wieder den p-Wert `r pv`.
Und der berechnete Punktschätzer für den Erwartungswert ist selbstverständlich
wieder durch `r statistic` gegeben,
der Annahmebereich ist jetzt [`r ci`]. Wir verwerfen auch mit diesem Niveau
die Nullhypothese nicht.

Mit der Funktion können wir auch einseitige Hypothesentests durchführen. Das müssen wir beim Aufruf der Funktion nur übergeben.


```{r reissgaussos,  message=FALSE, echo=TRUE, warnings=FALSE}
alpha <- 0.05
(res <- z.test(festigkeit, mu=100, sigma_0, 
              alternative="less",
              conf.level=1-alpha))
``` 

Mit den Ausgaben der Funktion erkennen wir, dass wir die Nullhypothese
nicht verwerfen.

## Der t-Test mit der Funktion *t.test*

Es ist nicht überraschend, dass der t-Test im Package *stat* in R
verfügbar ist. Die Funktion funktioniert ganz analog zu *z.test*,
so dass wir sofort den t-Test für unsere Reißfestigkeit durchführen können.


```{r reissstudent,  message=FALSE, echo=TRUE, warnings=FALSE}
alpha <- 0.05
(res <- t.test(festigkeit, mu=100, 
              conf.level=1-alpha))
``` 


```{r reissstudentvars,  message=FALSE, echo=FALSE, warnings=FALSE}
pv <- res$p.value
statistic <- res$estimate
ci <- res$conf.int
``` 

Als p-Wert erhalten wir  `r pv`.
Der Punktschätzer für den Erwartungswert `r statistic` verändert sich natürlich auch nicht. Der Annahmebereich  ist durch [`r ci`]. Wir verwerfen mit diesem Niveau
die Nullhypothese nicht.

Wiederum können wir einen einseitigen Test durchführen:

```{r reissstudentos,  message=FALSE, echo=TRUE, warnings=FALSE}
(res <- t.test(festigkeit, mu=100,
              alternative="less",
              conf.level=1-alpha))
``` 

Wir verwerfen diese Nullhypothese nicht.

## Tests für binomialverteilte Zufallsvariablen

Wir hatten das Beispiel einer binomailverteilten Zufallsvariable
betrachtet, für die wir einen Hypothesentest für den Anteil p
der defekten Bauteile durchgeführt haben. In R gibt es für diese
Tests die Funktion *prop.test*, die wir nun durchführen.

```{r binomRtest,  message=FALSE, echo=TRUE, warnings=FALSE}
p0 <- 0.03
n <- 500
alpha <- 0.05
p <- 20

(res <- prop.test(x=20, n, p=0.03, 
                 conf.level=1-alpha, 
                 correct=TRUE))
``` 

Wir verwerfen  die Nullhypothese nicht. 
Als Punktschätzer für p erhalten wir
`r res$estimate`, und als Annahmebereich das Intervall
[`r res$conf.int`]. 
Der berechnete p-Wert von `r res$p.value`
spricht ebenfalls dafür, die Nullhypothese nicht zu verwerfen.

Der Parameter *correct* kann verwendet werden, um zu steuern,
ob bei der Durchführung des Tests eine Stetigkeitskorrektur durchgeführt wird. 
Damit kann sichergestellt werden, dass die Annäherung der Binomialverteilung
durch eine Normalverteilung eine gute Qualität hat.