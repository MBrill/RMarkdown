---
title: "Fallstudie Tips - Vorhersagen mit linearen Modellen"
author: "Manfred Brill"
output: 
  
  html_document: 
    fig_caption: yes
    highlight: pygments
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_float: yes
  html_notebook: default
bibliography: ../literatur.bib    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
suppressPackageStartupMessages(library(dplyr))
library(tidyverse)
library(modelr)
library(kableExtra)
library(RColorBrewer)
myPalette <- brewer.pal(8, "Set3")
# Ausgabe von double-Werte mit  zwei Stellen hinter dem Komma
options(digits=3)
```

# Der Datensatz Tips
Der Datensatz enthält Angaben über Trinkgelder in einem US-amerikanischen Familienrestaurant aus den neunziger Jahren. Ursprünglich stammen die Daten aus [@bryant_95]. Der Datensatz wird in vielen Büchern zur Statistik und Datenanalyse. Die vorliegende Darstellung folgt [@cook_07] und [@theus_09],
die Daten stammen von der Website zu [@cook_07]. 
In einem Markdown-File haben wir die Daten eingelesen, eine Menge von 
Visualisierungen erstellt und ein weiteres Merkmal *Trinkgeldrate*
erzeugt. 
Diesen neuen Datensatz lesen wir mit *read_csv2* ein, er stellt die Basis für die
Betrachtung von Modellen für die Vorhersage des Trinkgelds dar.
Zur Überprüfung verwenden wir *kable* und geben die ersten Zeilen
der eingelesenen Daten aus.

```{r daten, message=FALSE, echo=TRUE, warnings=TRUE}
daten <- read_csv2("../data/tipsWithRate.csv")

kable(head(daten), align="l",
      caption="Tabelle 1: Die ersten Werte im Datensatz Tips") %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                full_width = T, 
                position = "center")
```

# Streuungsdiagramme 
Wir erstellen einige Streuungsdiagramme, um einen möglichen Zusammenhang
zwischen den Merkmalen und der Trinkgeldrate zu überprüfen.

```{r TrinkgeldrateScatter, message=FALSE, echo=TRUE}
ggplot(daten, 
       aes(x=Wochentag, y=Trinkgeldrate)) + 
  geom_jitter(color=myPalette[6],
             show.legend=FALSE,
             width=0.1,
             height=0.0) +
  scale_x_discrete(limits=c("Donnerstag", "Freitag", "Samstag", "Sonntag"),
                   breaks = c("Donnerstag", "Freitag", "Samstag", "Sonntag")) +  
  labs(
         title="Streuungsdiagramm Wochentag und Trinkgeldrate",
         x="",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsTagRate.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")

ggplot(daten, 
       aes(x=Wochentag, y=Trinkgeldrate, color=Tageszeit)) + 
  geom_jitter(show.legend=TRUE,
              width=0.1,
              height=0.0) +
  scale_x_discrete(limits=c("Donnerstag", "Freitag", "Samstag", "Sonntag"),
                   breaks = c("Donnerstag", "Freitag", "Samstag", "Sonntag")) +  
  labs(
         title="Streuungsdiagramm Wochentag und Trinkgeldrate",
         x="",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsTagRateTageszeit.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")

ggplot(daten, 
       aes(x=Anzahl, y=Trinkgeldrate)) + 
  geom_jitter(color=myPalette[6],
             show.legend=FALSE,
             width=0.1,
             height=0.0) +
  scale_x_discrete(limits=seq(1,6),
                   breaks=seq(1,6)) +
  labs(
         title="Streuungsdiagramm Anzahl der Gäste am Tisch und Trinkgeldrate",
         x="Anzahl der Gäste am Tisch",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsAnzahlRate.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")

ggplot(daten, 
       aes(x=Anzahl, y=Trinkgeldrate, color=Tageszeit)) + 
  geom_jitter(width=0.1,
              height=0.0) +
  scale_x_discrete(limits=seq(1,6),
                   breaks=seq(1,6)) +  
  labs(
         title="Streuungsdiagramm Anzahl der Gäste am Tisch und Trinkgeldrate",
         x="Anzahl der Gäste am Tisch",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsAnzahlRateTageszeit.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")
```

# Lineare Modelle
In der Literatur wird ein lineares Modell vorgeschlagen, das aus der Anzahl der
Personen am Tisch die Trinkgeldrate vorhersagt.
Wir betrachten im ersten Schritt dieses Modell.

## Lineare Modelle mit geom_smooth
Im ersten Schritt nutzen wir *geom_smooth*, mit dessen Hilfe wir
die Ausgleichsgerade direkt mit *ggplot* ausgeben können.
Dabei können wir auch Konfidenzintervalle für das berechnete Modell ausgeben.

```{r ggsmooth, message=FALSE, echo=TRUE, warnings = FALSE}
ggplot(daten, 
       aes(x=Anzahl, y=Trinkgeldrate)) + 
  geom_smooth(method=lm, 
              formula = y ~ x,
              se=FALSE,
              color=myPalette[1],
              size=1,
              fullrange = TRUE) +
  geom_jitter(color=myPalette[6],
              show.legend=FALSE,
              width = 0.1) +
  scale_x_discrete(limits=seq(1,6),
                   breaks=seq(1,6)) +   
  labs(
         title="Lineares Modell",
         subtitle="Berechnet mit geom_smooth(method=lm)",
         x="Anzahl der Gäste am Tisch",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsggsmooth.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")

# Mit Fehler-Bereich
ggplot(daten, 
       aes(x=Anzahl, y=Trinkgeldrate)) + 
  geom_smooth(method=lm, 
              se=TRUE,
              color=myPalette[1],
              size = 1) +
  geom_jitter(color=myPalette[6],
             show.legend=FALSE,
             width=0.1,
             height=0.0) +
  scale_x_discrete(limits=seq(1,6),
                   breaks=seq(1,6)) +   
  labs(
         title="Lineares Modell mit Konfidenzbereich",
         subtitle="Berechnet mit geom_smooth(method=lm)",
         x="Anzahl der Gäste am Tisch",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsggsmoothConf.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")

ggplot(daten, 
       aes(x=Anzahl, y=Trinkgeldrate)) + 
  geom_smooth(method=loess, 
              formula = y ~ x,
              se=FALSE,
              color=myPalette[1],
              size=1,
              fullrange = TRUE) +
  geom_jitter(color=myPalette[6],
              show.legend=FALSE,
              width = 0.1) +
  scale_x_discrete(limits=seq(1,6),
                   breaks=seq(1,6)) +   
  labs(
         title="Modell",
         subtitle="Berechnet mit geom_smooth(method=loess)",
         x="Anzahl der Gäste am Tisch",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsggsmoothLoess.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")
```

## Lineare Modelle mit lm
Wir verwenden Funktionen wie lm oder glm, berechnen das Modell und stellen
die Ergebnisse in der Grafik mit geoms wie *geom_abline* dar.

```{r lmModell, message=FALSE, echo=TRUE}
linearModel <- lm(Trinkgeldrate ~ Anzahl, data = daten)

linearModel.ab <- coef(linearModel)
linearModel.summary <- summary(linearModel)
linearModel.res <- linearModel.summary$residuals
```

Die berechnete Steigung für das lineare Modell ist `r linearModel.ab[2]`.
Der Achsenabschnitt ist  `r linearModel.ab[1]`. 
Das Bestimmungsmaß ist 
`r linearModel.summary$r.squared`, also nicht sehr hoch.

Die Ausgaben der Funktion *summary* geben eine ausführliche Diagnose aus, da uns insbesondere die p-Werte interessieren.

```{r lmSummary, message=FALSE, echo=TRUE}
linearModel.summary
```

Da wir die p-Werte, die hier ausgegeben werden häufiger verwenden
einige Bemerkungen dazu. Diese Werte stammen aus einem Hypothesentest.
Dabei ist die Nullhypothese, dass es keinen linearen Zusammenhang
zwischen der Anzahl der Personen und der Trinkgeldrate gibt.
Die Gegenhypothese ist natürlich das Gegenteil, dass es einen Zusammenhang
gibt. Die p-Werte für die beiden berechneten Koeffizienten geben die Wahrscheinlichkeit
dafür an, dass die berechneten Werte angenommen werden, falls die Nullhypothese
gilt. Der p-Wert für die Steigung ist nicht sehr hoch, deshalb hat er nur
einen Stern. Trotzdem verwerfen wir die Nullhypothese und gehen
von einem Zusammenhang aus.

Jetzt können wir die in *linearModel.ab* gespeicherten Koeffizienten
der berechneten Gerade verwenden und geben die Gerade im Streuungsdiagramm
mit *geom_abline* mit aus.

```{r abline, message=FALSE, echo=TRUE}
ggplot(daten, 
       aes(x=Anzahl, y=Trinkgeldrate)
       ) + 
  geom_abline(aes(intercept=linearModel.ab[1], slope=linearModel.ab[2]), 
              color=myPalette[1],
              size=1.0) +
  geom_jitter(color=myPalette[6],
             show.legend=FALSE,
             width=0.1,
             height=0.0) +
  scale_x_discrete(limits=seq(1,6),
                   breaks=seq(1,6)) + 
  labs(
         title="Lineares Modell",
         x="Anzahl der Gäste am Tisch",
         y="Trinkgeldrate"
  ) 

ggsave(filename="tipsabLine.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")
```

Wir fügen jetzt unserem Datensatz die Residuen hinzu und geben einen Residualplot aus. 
Wir könnten dies aus der Variablen *linearModel* ablesen, aber wir verwenden das Package
*modelr* aus *tidyverse* und die Funktion *add_residuals*. 
Wir erhalten eine weitere Spalte in unserem Datensatz mit dem Bezeichner *resid*.

```{r resPlot, echo=TRUE, message=FALSE}
daten1 <- daten %>%
  add_residuals(linearModel)

# Residualplot
ggplot(daten1, aes(Anzahl, resid)) + 
  geom_ref_line(h=0,
                colour = "red",
                size = 0.5) + 
  geom_point(size=2.0, color="orange") +
  labs(
    title="Residualplot für das lineare Modell Trinkgeldrate ~ Anzahl der Personen", 
    x="Anzahl der Personen", 
    y="Residuen"
  ) 

ggsave(filename="tipsResid.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")
```

```{r predictionx, echo=TRUE}
# Wir erzeugen die Werte, die wir einsetzen als data.frame
persons <- tibble(Anzahl = c(4,6,7,8))
```

Wir erzeugen jetzt einige Vorhersagen mit Hilfe der Funktion *predict*. 
Die Anzahl der Personen, für die wir die Vorhersagen machen möchten
speichern wir in einem Tibble ab. 
Wir betrachten Vorhersagen für `r persons$Anzahl[1]`, `r persons$Anzahl[2]`, `r persons$Anzahl[3]` und `r persons$Anzahl[4]` Personen.

```{r predictions, echo=TRUE}
# Wir setzen das berechnete Modell und die neuen Werte in predict ein
linearModel.predictions <- predict(linearModel, persons)
```

# Empfehlungen für Trinkgelder

Wir machen jetzt Vorhersagen für eine verschiedene Anzahlen von Personen und
an einem Tisch
und einer Rechnungshöhe. Das lineare Modell sagt für eine Anzahl die Trinkgeldrate voraus,
aus der wir mit der Rechnungshöhe das Trinkgeld empfehlen.

```{r predTable, echo=TRUE}
tip.prediction <- persons %>%
  mutate(
    Rechnung = c(10.0, 20.0, 30.0, 30.0),
    Trinkgeldrate = linearModel.predictions,
    Trinkgeldempfehlung = Trinkgeldrate * Rechnung
  ) %>%
  select(Anzahl, Rechnung, Trinkgeldempfehlung)

kable(tip.prediction,
      align="l",
      caption="Tabelle 2: Empfehlungen für das Trinkgeld auf der Basis des linearen Modells Anzahl ~ Trinkgeldrate",
            col.names=c("Anzahl der Personen", "Rechnungshöhe", "Empfohlenes Trinkgeld")) %>%
      kable_styling(
        bootstrap_options = c("striped", "condensed"), 
       full_width = T, 
       position = "center")
```

# Weitere lineare Modelle
Wir können uns natürlich fragen, ob das in der Literatur vorgeschlagene Modell
wirklich die beste Lösung ist. Deshalb werden wir in diesem Abschnitt
noch weitere Modelle erstellen und gegenseitig vergleichen.

## Vorhersagen mit Hilfe der Merkmale Rechnungshöhe
Wir könnten natürlich statt mit dem neu eingeführten Merkmal *Trinkgeldrate*
eine Empfehlung direkt aus der Rechnungshöhe berechnen.

```{r lmModell2, message=FALSE, echo=TRUE}
linearModel2 <- lm(Trinkgeld ~ Rechnung, data = daten)

linearModel2.ab <- coef(linearModel2)
linearModel2.summary <- summary(linearModel2)
linearModel2.res <- linearModel2.summary$residuals

linearModel2.summary
```

Die berechnete Steigung für das lineare Modell ist `r linearModel2.ab[2]`.
Der Achsenabschnitt ist  `r linearModel2.ab[1]`. 
Das Bestimmungsmaß ist `r linearModel2.summary$r.squared`.
Wir erhalten eine deutlich höheres Bestimmungsmaß als für das Modell
aus der Literatur. Wir erstellen eine grafische Darstellung dieses Modells
in einem Streuungsdiagramm.

```{r abline2, message=FALSE, echo=TRUE}
ggplot(daten, 
       aes(x=Rechnung, y=Trinkgeld)
       ) + 
  geom_abline(aes(intercept=linearModel2.ab[1], slope=linearModel2.ab[2]), 
              color=myPalette[1],
              size=1.0) +
  geom_jitter(color=myPalette[6],
             show.legend=FALSE,
             width=0.1,
             height=0.0) +
  labs(
         title="Lineares Modell Trinkgeld ~ Rechnungshöhe",
         x="Höhe der Rechnung in Dollar",
         y="Trinkgeld in Dollar"
  ) 

ggsave(filename="tipsabLine2.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")
```

Wir machen einige Vorhersagen, wie schon vorher. 
Wir erzeugen jetzt einige Vorhersagen mit Hilfe der Funktion *predict*. 
Die Anzahl der Personen, für die wir die Vorhersagen machen möchten
speichern wir in einem Tibble ab. 
Wir betrachten Vorhersagen für `r persons$Anzahl[1]`, `r persons$Anzahl[2]`, `r persons$Anzahl[3]` und `r persons$Anzahl[4]` Personen.

```{r predictions2, echo=TRUE}
bills <- tibble(Rechnung = c(10.0, 20.0, 30.0, 30.0))

linearModel2.predictions <- predict(linearModel2, bills)

tip2.prediction <- bills %>%
  mutate(
    Trinkgeld = linearModel2.predictions
  )

kable(tip2.prediction,
      align="l",
      caption="Tabelle 3: Empfehlungen für das Trinkgeld auf der Basis des linearen Modells Trinkgeld ~ Rechnungshöhe",
            col.names=c("Rechnung in Dollar", "Empfohlenes Trinkgeld in Dollar")) %>%
      kable_styling(
        bootstrap_options = c("striped", "condensed"), 
       full_width = T, 
       position = "center")
```

Bevor wir die beiden Vorhersagen vergleichen erstellen wir einen Residualplot
für das Modell *Rechnung ~ Trinkgeld*.


```{r resPlot2, echo=TRUE, message=FALSE}
daten2 <- daten %>%
  add_residuals(linearModel2)

# Residualplot
ggplot(daten2, aes(Rechnung, resid)) + 
  geom_ref_line(h=0,
                colour = "red",
                size = 0.5) + 
  geom_point(size=2.0, color="orange") +
  labs(
    title="Residualplot für das lineare Modell Trinkgeld ~ Rechnung", 
    x="Rechnungshöhe in Dollar", 
    y="Residuen"
  ) 

ggsave(filename="tipsResid2.png", 
       plot=last_plot(), 
       device="png",
       path="../images/", 
       width=16, 
       height=9, 
       units="cm")

rm(daten2)
```

Der Residualplot für dieses Modell sieht, bis auf einige Ausreißer für sehr kleinen und sehr großen Rechnungshöhen, ebenfalls gut aus, so dass wir jetzt ein zweites lineares Modell für die Vorhersage des
Trinkgelds haben. Wir vergleichen nochmals beide Vorhersagen
in einer Tabelle.

```{r evaluation, echo=TRUE, message=FALSE}
predictions <- tibble(tip.prediction$Rechnung, 
                      tip.prediction$Trinkgeldempfehlung,
                      tip2.prediction$Trinkgeld)
kable(predictions,
      align="l",
      caption="Tabelle 4: Empfehlungen für das Trinkgeld",
            col.names=c("Rechnungshöhe in Dollar", "Trinkgeld-Empfehlung Modell 1 in Dollar", "Trinkgeld-Empfehlung Modell 2 in Dollar")) %>%
      kable_styling(
        bootstrap_options = c("striped", "condensed"), 
       full_width = T, 
       position = "center")
```

Bereits diese Tabelle zeigt uns, dass das Modell *Rechnung ~ Trinkgeld* deutlich höhere
Empfehlungen ausgibt.

## Ein multilineares Modell
Bevor wir einen Blick darauf werfen, wie wir verschiedenen Modelle vergleichen uns
eine Entscheidung treffen, welches wir letztendlich verwenden, erstellen wir
ein weiteres Modell. Wir können lineare Modelle mit mehr als einem Einflussfaktor
aufbauen. Dann ist es nicht mehr ganz so leicht die Ergebnisse zu visualisieren,
aber es liegt nahe beide bisher erstellten Modelle zu kombinieren und
sowohl die Anzahl der Personen und die Rechnungshöhe in ein Modell einzubauen.

```{r multi1, echo=TRUE, warning=TRUE}
multiModel1 <- lm(Trinkgeld ~ Anzahl+Rechnung, data = daten)

multiModel1.ab <- coef(multiModel1)
multiModel1.summary <- summary(multiModel1)

multiModel1.summary
```

Der p-Wert für das Merkmal Anzahl ist nachwievor sehr klein. Wir könnten jetzt neue
Vorhersagen für das Trinkgeld machen. Aber darauf verzichten wir und betrachten jetzt
das generelle Vorgehen im supervised machine learning.

Vergleicht man die Bestimmungsmaße für die Modelle *Trinkgeld ~ Rechnung*
und Trinkgeld ~ Rechnung + Anzahl*, dann erkennt man, dass der Wert für das Modell
mit zwei Merkmalen leicht höher ist. 
Das ist zu erwarten - je mehr Merkmale wir in einem Modell haben, desto höher
ist das Bestimmungsmaß. Es stellt sich nur die Frage, wie hoch der Unterschied  zwischen
beiden Werten ist.

# Auswahl der Merkmale für ein Modell
Wir haben bisher drei Modelle erstellt, darunter ein multilineares Modell.
Im machine learning gibt es verschiedene Strategien, wie man eine Entscheidung
trifft, welche Merkmale letztendlich in das verwendete Modell eingehen sollen.
Wir könnten natürlich auf die Idee kommen *alle* möglichen Kombinationen
aufzubauen und dann zu vergleichen. Das ist aber keine gute Idee, denn die
Kombinatorik sagt uns, dass dies viel zu viele Möglichkeiten sein werden.
Deshalb gibt es insgesamt drei Strategien, wie wir solche Merkmale auswählen.
Die Darstellung folgt dabei [@tibshirani_13] auf den Seiten 78 und 79.
Bevor wir die drei Strategien beschreiben müssen wir uns klar machen,
dass wir natürlich auf jeden Fall ein Kriterium benötigen. Häufig legen
wir einen p-Wert für ein Merkmal fest, der nicht überschritten werden darf.

## Forward Selection

1. Wir beginnen mit einem *Null-Modell*, das kein Einflussgröße und nur einen Achsenabschnitt
enthält. Mit anderen Worten wir verwenden eine konstante Vorhersage.
1. Anschließend erstellen wir für alle p Einflussgrößen in den Daten ein
lineares Modell und untersuchen die Fehler und die Bestimmungsmaße
für diese Modelle.
1. Wir fügen das *beste* Merkmal aus diesen p Modellen zu unserem Modell hinzu.
1. Anschließend wiederholen wir das Vorgehen und erstellen ein multilineares Modell,
indem wir jedes der verbleibenden p-1 Merkmale hinzufügen und wählen wieder das beste
davon aus. Wir überprüfen, ob wir abbrechen, falls nicht, wiederholen wir diese Schritte,
bis wir ein Modell erreicht haben, das wir verwenden.

## Backward Selection

1. Wir beginnen mit allen Merkmalen im Datensatz und erstellen ein multilineares Modell,
das alle Merkmale enthält.
1. Wir betrachten die p-Werte dieser Merkmale und entfernen das Merkmal aus dem Modell,
das den größten p-Wert enthält (falls es p-Werte gibt, die oberhalb unserer gewählten Schranke liegen).
1. Wir erstellen ein Modell mit den verbliebenen p-1 Merkmalen und gehen wie
im vorherigen Schritt vor.
1. Dies führen wir durch, bis ein Abbruchkriterium erreicht ist.

## Mixed Selection

Dieses Vorgehen ist ein Kombination aus forward und backward selection.

1. Wir beginnen mit dem Null-Modell, also keine Einflussgrößen.
1. Wir fügen wie in der forward selection das beste Modell mit einer Einflussgröße hinzu.
1. Wir fügen sukzessive weitere Merkmale hinzu. Sollte es ein Merkmal geben,
dessen p-Wert unser Kriterium verletzt, entfernen wir dieses Merkmal aus unserem Modell.
1. Wir fügen sukzessive die verbliebenen Merkmale hinzu.

Ergebnis dieses Vorgehens ist ein Modell, das nur die Merkmale enthält, die
von uns akzeptierte p-Werte aufweisen.

## Backward Selection für die Vorhersage von Trinkgeldern.

```{r pBarrier}
pV <- 0.0001
```

Wir führen exemplarisch backward selection für unser Beispiel durch.
Als schranke für die p-Werte legen wir hier ´r pV` <- 0.0001` fest.
Wir haben mehrere Faktoren in den Daten. Dies ist für die Funktion *lm*
jedoch kein Problem, für diese Merkmale führt die Funktion Dummy-Variablen
ein.

```{r multiFull, echo=TRUE, warning=TRUE}
multiModel.Full <- lm(Trinkgeld ~ ., data = daten)

multiModel.Full.ab <- coef(multiModel.Full )
multiModel.Full.summary <- summary(multiModel.Full )

multiModel.Full.summary
```

Das Ergebnis zeigt uns, dass eigentlich nur drei Merkmale übrig bleiben.
Dabei enthalten die Daten sowohl die Rechnungshöhe als auch die Trinkgeldrate,
die natürlich voneinander abhängen. Um dies zu kompensieren erstellen wir
zwei Varianten unserer Daten und wiederholen unser Experiment.

```{r multiFull1, echo=TRUE, warning=TRUE}
daten.Orig <- daten %>%
  select(-Trinkgeldrate)
  
multiModel.Full1 <- lm(Trinkgeld ~ ., data = daten.Orig)

summary(multiModel.Full1)
```

Jetzt bleibt eigentlich nur die Rechnungshöhe als signifikanter Einflussfaktor übrig.
Am höchsten sind die p-Werte für die Wochentage, so dass wir jetzt ein Modell bauen
ohne dieses Merkmal.

```{r multiFull11, echo=TRUE, warning=TRUE}
multiModel.Full11 <- lm(Trinkgeld ~ .-Wochentag, data = daten.Orig)

summary(multiModel.Full11)
```
Das Bestimmungsmaß wird leicht kleiner, aber nur um sehr wenig. Wir können vermuten,
dass wir auch das Merkmal Tageszeit entfernen können, was wir auch tun.

```{r multiFull12, echo=TRUE, warning=TRUE}
multiModel.Full12 <- lm(Trinkgeld ~ .-Wochentag-Tageszeit, data = daten.Orig)

summary(multiModel.Full12)
```

Das machen wir jetzt weiter und entfernen sukzessive das Merkmal Geschlecht
und auch Raucher.

```{r multiFull13, echo=TRUE, warning=TRUE}
multiModel.Full13 <- lm(Trinkgeld ~ .-Wochentag -Tageszeit - Geschlecht, data = daten.Orig)

summary(multiModel.Full13)

multiModel.Full14 <- lm(Trinkgeld ~ .-Wochentag -Tageszeit - Geschlecht -  Raucher, data = daten.Orig)

summary(multiModel.Full14)
```

Jetzt sind wir in der Situation angelangt, die wir schon betrachtet hatten. Ausser der Rechnungshöhe
ist nur noch die Anzahl der Gäste am Tisch übrig, die aber auch einen p-Wert hat, der oberhalb
unserer gewählten Schranke liegt.

Wir wiederholen der Vollständigkeit halber dieses Vorgehen und erzeugen jetzt
Vorhersagen für die Trinkgeldrate und führen backward selection durch.
Dabei verwenden wir einen Datensatz, aus dem wir Rechnungshöhe und Trinkgeld entfernen.

```{r multiFull2, echo=TRUE, warning=TRUE}
daten.Rate <- daten %>%
  select(-Rechnung, -Trinkgeld)
  
multiModel.Full21 <- lm(Trinkgeldrate ~ ., data = daten.Rate)
summary(multiModel.Full21)

```

Hier können wir schon nach einem Schritt beenden. Das Merkmal *Anzahl* ist noch am Besten,
aber wie schon in unserer vorherigen Betrachtung ist das Bestimmungsmaß sehr klein
und der p-Wert ist deutlich oberhalb der von  uns festgelegten Grenze.

# Plausibilitätsbetrachtungen
Jetzt können wir eine Entscheidung für ein Modell fällen, aber es fragt sich,
wie gut dieses Modell sich dann verhält. Im machine learning gibt es weitere
Strategieren, um verschiedene Modelle auf ihre Plausibilität zu überprüfen.
Dazu verwendet man den sogenannten *validation set approach*, den wir im Folgenden
kurz betrachten. 

Im *validation set approach* teilen wir die uns zur Verfügung stehenden Daten
in zwei Teile auf. Wir verwenden eine Teilmenge unserer Daten als *Trainingsmenge*
und erstellen das Modell auf dieser Basis. Das Komplement der Trainingsmenge
nennen wir *Testmenge*. Diese Teilmenge verwenden wir, um die Performanz
der untersuchten Modelle zu beurteilen. Wir betrachten hier nur das prinzipielle
Vorgehen, in der Literatur finden Sie weiter gehende Ansätze wie
*cross-validation* oder *bootstrap*. Dies finden Sie zum Beispiel in [@tibshirani_13]
und anderen Büchern zu machine learning.

Wir führen diesen validation set approach sowohl für unser Modell *Rechnung ~ Trinkgeld*
als auch für das in der Literatur vorgeschlagene Modell *Trinkgeldrate ~ Anzahl*
durch. Wir haben im vorherigen Abschnitt bereits die zwei tibbles *daten.Orig*
ohne die Trinkgeldrate und *daten.Rate* für die Variante mit der Trinkgeldrate.

## Validierung des Modells *Trinkgeld ~ Rechnung*

```{r testn, echo=TRUE, warnings = TRUE}
test.n <- 20
```

Wir verfügen insgesamt über `r nrow(daten)` Zeilen in unserem Datensatz.
Wie wir diese Menge aufteilen ist uns überlassen. Wir entscheiden uns hier dazu,
aus diesen `r nrow(daten)` Zeilen `r test.n` für den Test und die restlichen 
für das Training der Modelle zu verwenden. 
Wir wählen diese `r test.n` Zeilen mit Hilfe eines Zufallszahlengenerators 
aus. Wenn wir für den Zufallszahlengenerator einen seed-Wert verwenden
werden die Ergebnisse in dieser Datei reproduzierbar. Dies würden wir in der Praxis
später natürlich nicht machen, wird hier aber verwendet, um Ihnen das Nachvollziehen
des Vorgehens zu erleichtern.

```{r testSample, echo=TRUE, warnings = TRUE}
set.seed(42)
n <- nrow(daten)
train.n <- n - test.n
train <- sample(n, train.n)
```

Jetzt sind wir in der Lage mit unserer Trainingsmenge ein lineares Modell
aufzubauen. Die Funktion *lm* bietet dafür ein Argument *subset* an, das wir
dazu verwenden. Wir verwenden dabei das tibble *daten.Orig* ohne die Trinkgeldrate.

```{r train1, echo=TRUE, warnings=TRUE}
train1.model <- lm(Trinkgeld ~ Rechnung, data = daten.Orig, subset=train)

summary(train1.model)
```

Die Ergebnisse unterscheiden sich nicht sehr stark von dem Modell, das wir bereits berechnet hatten.
Welches Maß verwenden wir jetzt für die Beurteilung der Qualität des Modells.
Dazu gibt es zwei Werte, die wir berechnen. Wir erinnern uns, die Koeffizienten
in unserem linearen Modell wurden so berechnet, dass die mittlere quadratische
Abweichung zwischen den y-Werten und den durch das berechnete Modell gegebenen theoretischen
Werte minimal wurde. Dieser Wert ist der sogenannten *Mean Squared Error* *MSE*,
der durchschnittliche Wert der Fehlerquadrate.
Für *MSE* gibt es jetzt sogar zwei Werte. Einmal MSE für die Trainingsdaten, die aber nicht
sehr interessant sind. Denn wir haben das Modell so gebaut, dass dieser Wert minimal wird.
Aber wir können auch den Testfehler berechnen - den MSE für die Werte aus
der Testmenge. Dort vergleichen wir die mittlere Abweichung zwischen
den y-Werte in der Testmenge (das sind die Trinkgelder, die wirklich bezahlt wurden)
und den durch unser Modell vorgesagten Trinkgelder. Diese Vorhersagen können
wir wie bereits durchgeführt mit Hilfe der Funktion *predict* berechnet werden.
Mittelwerte berechnen wir mit Hilfe der Funktion *mean*. 
Insgesamt geht die Berechnung dieses Testfehlers sehr effizient in R.

```{r testMSE1, echo=TRUE, warnings=TRUE}
train1.predictions <- predict(train1.model, daten.Orig)[-train]
train1.diff <- (daten.Orig$Trinkgeld[-train] - train1.predictions)^2
train1.MSE <- mean(train1.diff)
```
Wir erhalten einen Testfehler von `r train1.MSE`. Wir können auf die gleichen Weise den Trainingsfehler berechnen. Diesen Wert finden wir aber bereits in den Ausgaben von *summary*
unter dem Begriff *residual standard error*. Hier ist der durch *1.01* gegeben.

Wenn wir einen anderen seed-value für den Zufallzahlengenerator verwenden und das Experiment
wiederholen erhalten wir natürlich einen anderen Wert für den Testfehler. Es spricht nichts dagegen
dies durchzuführen und  anschließend den mittleren Testfehler zu berechnen. Dieser Wert
hat eine noch höhere Qualität für unsere Entscheidung.

## Validierung des Modells *Trinkgeldrate ~ Anzahl*
Wir wiederholen unser Vorgehen und validieren das Modell, das die Trinkgeldrate verwenden.
Wir verwenden die gleiche Aufteilung in Trainings- und Testmenge und berechnen abschließend
den Testfehler. 

```{r train2, echo=TRUE, warnings=TRUE}
train2.model <- lm(Trinkgeldrate ~ Anzahl, data = daten.Rate, subset=train)
summary(train2.model)

train2.predictions <- predict(train2.model, daten.Rate)[-train]
train2.diff <- (daten.Rate$Trinkgeldrate[-train] - train2.predictions)^2
train2.MSE <- mean(train2.diff)
```

Wir erhalten einen Testfehler in Höhe von `r train2.MSE` für die Trinkgeldrate.
Jetzt fügen wir eine Berechnung hinzu, um die Trinkgelder aus
der Trinkgeldrate zu berechnen und dafür die mittlere quadratische Abweichung zu berechnen, um die beiden Modelle fair zu vergleichen.

```{r train2Trinkgeld, echo=TRUE, warnings=TRUE}
# Wir benötigen die Rate, die Anzahl und die Höhe der Rechnung 
train2.Trinkgeld <- train2.predictions * daten.Orig$Rechnung[-train]
train2.diffTrinkgeld <- (train2.Trinkgeld - train2.predictions)^2
train2.MSETrinkgeld <- mean(train2.diffTrinkgeld)
```

Wenn wir die Trinkgelder aus unserem Modell berechnen erhalten wir ein mittlere quadratische 
Abweichung zwischen vorgesagtem Trinkgeld und dem wirklich bezahlten Trinkgeld
von `r train2.MSETrinkgeld`, der deutlich schlechter ist als der Wert für unser
Modell `Trinkgeld ~ Rechnung*. Dies spricht für dieses Modell.

## Ausblick
Auch hier können wir wieder verschiedene Trainingsmengen verwenden und eine noch bessere
Entscheidungsgrundlagen bilden. Dies geht soweit, dass wir *leave-one-out cross-validation*
durchführen könnten. Wir verzichten auf die zufällige Auswahl der Trainingsmenge, sondern lassen
bilden `r n` Modelle, in denen wir jeweils nur eine Zeile der Daten weglassen. 
Wir berechnen den jeweiligen Testfehler und bilden daraus den Mittelwert als Wert,
den wir für die Entscheidung verwenden. Man kann sich gut vorstellen, dass für dieses
Vorgehen der Rechenaufwand schnell sehr groß wird. In R gibt es dafür Packages,
die dies unterstützen.

In der Statistik gibt es die Mittelwertregel *"*Messe häufig und bilde Mittelwerte*.
Dadurch können wir die Streuung unserer Vorhersagen stark verkleinern. 
Deshalb liegt es nache eine Menge von Trainingsmengen zu bilden, die Vorhersagen
zu berechnen und diese nochmals zu mitteln. Dies wird die Vorhersagen deutlich
verbessern. Dieses Vorgehen finden wir unter den Stichworten *Bootstrap*
und *Boosting* im machine learning.

# Literatur